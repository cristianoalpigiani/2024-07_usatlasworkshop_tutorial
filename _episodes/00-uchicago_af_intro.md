---
title: "UChicago Analysis Facility"
teaching: 5
exercises: 0
questions:
- " Why having an Analysis Facility at US-ATLAS?"
objectives:
- " Understanding: US-ATLAS Shared Tier-3 Analysis Facility at UChicago"
- " Provide contact information and documentation sources"
keypoints:
- " Having an Analysis Facility located in the US is a great oportunity to simplify and accelerate the delivery of HEP results"
- " Check the documentation sources and the different contact informations for help, user support, feedback, news, etc! "
- " Several shared analysis, software & computing resources resources are available, please use them and provide feedback" 
---

<br>

US ATLAS has three shared Tier 3 analysis facilities providing software & computing resources, one of the most recent is located at The University of Chicago and was pre-launched in October 2021.

**<center> Funded by NSF (National Science Foundation) and co-located with MWT2-UC </center>**

![image info](./../fig/i_sharedtier3.png){: .image-with-shadow }

<br>

- <strong>Large login nodes</strong> for develpment & batch pools or larger-scale processing
- <strong>Storage</strong> for local datasets & XCache for remote datasets
- Access to ATLAS <strong>analysis software and tools</strong>

Broad range of activities carried out & supported at the facilities, including:
- <strong>Event generation</strong>, <strong>detector simulation</strong> with ATLAS or standalone software
- <strong>Data movement</strong> (via R2D2) and access (using Xcache)
- <strong>Data processing</strong> for analysis & statistics using ATLAS software in CVMFS
- Graphical applications for example via X-windows
- Software development, testing code before submitting to batch system or Panda
- <strong>Supported for Run 3 but also allow for R&D for the future</strong>

<br>

> ## Software & Computing Resources
> - Resources that <font color="LimeGreen"><strong>fill gaps between grid jobs and interactive analysis on local computers</strong></font>
> - ssh access and <font color="LimeGreen"><strong>HTCondor</strong></font> batch
> - Simple <font color="LimeGreen"><strong>Jupyter notebook</strong></font> scheduling to CPU and GPU
> - Coffea-Casa, ServiceX (IRIS-HEP tools for <font color="LimeGreen"><strong>columnar analysis</strong></font>)
> - Interactive access: interactive nodes, containers, node flavors
> - Processing interfaces: HTCondor access, shared endpoint.
> - <strong>~1000 cores co-located and close integration with MWT2. ~1 petabyte of storage</strong>
> - Users start with: 5TB $DATA, 100GB $HOME, 1500 shared CPU cores, shared GPUs.
{: .callout}

![image info](./../fig/i_aboutpage.png){: .image-with-shadow }

> ## Contact info
>
> - Join our  <a href="https://atlas-talk.sdcc.bnl.gov/"> US-ATLAS Discourse Forum</a> for help, questions, comments, user support, newsletter and more!. 
>
> - Check the <a href="https://usatlas.readthedocs.io/projects/af-docs/en/latest/">public documentation for US-ATLAS Analysis Facilities</a>
>
{: .callout}

{% include links.md %}
